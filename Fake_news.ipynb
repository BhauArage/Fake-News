{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_news.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhauArage/Fake-News/blob/main/Fake_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NcQFeknGvnY"
      },
      "source": [
        "**Importing Necessary Libraries and Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRMC77HhHXFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60430fa-bdaa-445a-91fc-97fedaf54280"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Core packages for text processing.\n",
        "\n",
        "import string\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Loading some sklearn packages for modelling.\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# Some packages for word clouds and NER.\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Loading pytorch packages.\n",
        "\n",
        "import torch\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "stop = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDP8MnbcICSk"
      },
      "source": [
        "**Using GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsiyisknOoBn",
        "outputId": "0dcd6514-c946-46f7-f7a1-4c4ee9e4a9e8"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device('cuda')    \n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rmCRQiDSXGp",
        "outputId": "7c1ff942-6321-48bc-f561-9c8589e49c00"
      },
      "source": [
        "print('Using device:', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFDwA7UYGlXw"
      },
      "source": [
        "**Reading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "WBdKL7yaSaBL",
        "outputId": "e204cc1a-2ce5-41ba-9b07-0289ff08dd88"
      },
      "source": [
        "test=pd.read_csv('/test.csv')\n",
        "train=pd.read_csv('/train.csv')\n",
        "\n",
        "\n",
        "print(f'Number of training tweets: {train.shape[0]}\\n')\n",
        "print(f'Number of training tweets: {test.shape[0]}\\n')\n",
        "\n",
        "display(train.sample(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training tweets: 20800\n",
            "\n",
            "Number of training tweets: 5200\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3786</th>\n",
              "      <td>3786</td>\n",
              "      <td>In Consideration of the Supreme Importance of ...</td>\n",
              "      <td>Les Visible</td>\n",
              "      <td>By Les Visible on November 4, 2016 Visible Ori...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8814</th>\n",
              "      <td>8814</td>\n",
              "      <td>Long-term Effects of the Presidential Election</td>\n",
              "      <td>jhamilton</td>\n",
              "      <td>November 10, 2016 Long-term Effects of the Pre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5856</th>\n",
              "      <td>5856</td>\n",
              "      <td>There’s More to Rosé Than You May Think - The ...</td>\n",
              "      <td>Eric Asimov</td>\n",
              "      <td>Summer arrives, and along with it, rosé and en...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9881</th>\n",
              "      <td>9881</td>\n",
              "      <td>Hillary Clinton and Donald Trump, Ages 68 and ...</td>\n",
              "      <td>Patrick Healy</td>\n",
              "      <td>Donald J. Trump and Hillary Clinton have been ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14893</th>\n",
              "      <td>14893</td>\n",
              "      <td>The Other 13 Women Testifying Against Cosby .....</td>\n",
              "      <td>Graham Bowley and Sydney Ember</td>\n",
              "      <td>Some knew him for only a day. Others built fri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>166</td>\n",
              "      <td>Takata Chief Executive to Resign as Financial ...</td>\n",
              "      <td>Jonathan Soble</td>\n",
              "      <td>TOKYO  —   The chief executive of Takata said ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4694</th>\n",
              "      <td>4694</td>\n",
              "      <td>Millions of South Koreans Rise Up Against Shad...</td>\n",
              "      <td>Madeline</td>\n",
              "      <td>Your News Wire \\nSouth Koreans are rising up i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19600</th>\n",
              "      <td>19600</td>\n",
              "      <td>Fox News Channel Cancels ’Red Eye’ - Breitbart</td>\n",
              "      <td>Daniel Nussbaum</td>\n",
              "      <td>Fox News Channel has canceled its     news pro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1674</th>\n",
              "      <td>1674</td>\n",
              "      <td>30 Civilians Die In US Airstrike Called ‘To Pr...</td>\n",
              "      <td>The Guardian</td>\n",
              "      <td>Videos 30 Civilians Die In US Airstrike Called...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14968</th>\n",
              "      <td>14968</td>\n",
              "      <td>Pee Wee Football Team Banned From League After...</td>\n",
              "      <td>Kim Smith</td>\n",
              "      <td>Lifesize Noah’s Ark Is Massive Success Despite...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... label\n",
              "3786    3786  ...     1\n",
              "8814    8814  ...     1\n",
              "5856    5856  ...     0\n",
              "9881    9881  ...     0\n",
              "14893  14893  ...     0\n",
              "166      166  ...     0\n",
              "4694    4694  ...     1\n",
              "19600  19600  ...     0\n",
              "1674    1674  ...     1\n",
              "14968  14968  ...     1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jXFjw_iFeiT"
      },
      "source": [
        "labels = train['label'].values\n",
        "idx = len(labels)\n",
        "combined = pd.concat([train, test])\n",
        "combined = combined.fillna('no data')\n",
        "df = combined['title'] + ' ' + combined['author']\n",
        "combined = df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr5XC-4cKv9t",
        "outputId": "eccd6c72-67c2-4ef0-f689-8531efebeee8"
      },
      "source": [
        "combined"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['House Dem Aide: We Didn’t Even See Comey’s Letter Until Jason Chaffetz Tweeted It Darrell Lucus',\n",
              "       'FLYNN: Hillary Clinton, Big Woman on Campus - Breitbart Daniel J. Flynn',\n",
              "       'Why the Truth Might Get You Fired Consortiumnews.com', ...,\n",
              "       'California Today: What, Exactly, Is in Your Sushi? - The New York Times Mike McPhate',\n",
              "       '300 US Marines To Be Deployed To Russian Border In Norway no data',\n",
              "       'Awkward Sex, Onscreen and Off - The New York Times Teddy Wayne'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL4w6aQh-NQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "123da29b-0326-4761-d7bf-c71f7a33898b"
      },
      "source": [
        "Tokenizer=BertTokeizer.from_pretrained('bert-base-case')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-34c5f8bc0ca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBertTokeizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-case'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'BertTokeizer' is not defined"
          ]
        }
      ]
    }
  ]
}